{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (2.1.4)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (1.26.3)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (61 kB)\n",
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.2-cp310-cp310-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (1.3.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from statsmodels) (1.11.4)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: pillow>=8 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: six in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Downloading statsmodels-0.14.2-cp310-cp310-macosx_11_0_arm64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-macosx_12_0_arm64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.8.4-cp310-cp310-macosx_11_0_arm64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.2.1-cp310-cp310-macosx_11_0_arm64.whl (244 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.8/244.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp310-cp310-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached kiwisolver-1.4.5-cp310-cp310-macosx_11_0_arm64.whl (66 kB)\n",
      "Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.9/233.9 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, numpy, kiwisolver, fonttools, cycler, patsy, pandas, contourpy, statsmodels, scikit-learn, matplotlib\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.1.4\n",
      "    Uninstalling pandas-2.1.4:\n",
      "      Successfully uninstalled pandas-2.1.4\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.2\n",
      "    Uninstalling scikit-learn-1.3.2:\n",
      "      Successfully uninstalled scikit-learn-1.3.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker 2.203.1 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 kiwisolver-1.4.5 matplotlib-3.8.4 numpy-1.26.4 pandas-2.2.2 patsy-0.5.6 pyparsing-3.1.2 scikit-learn-1.4.2 statsmodels-0.14.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pandas numpy statsmodels scikit-learn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting machine-learning-datasets\n",
      "  Downloading machine_learning_datasets-0.1.23-py3-none-any.whl.metadata (994 bytes)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (3.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (1.26.4)\n",
      "Collecting opencv-python<5.0.0,>=4.5.1 (from machine-learning-datasets)\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl.metadata (20 kB)\n",
      "Collecting pandas<2.0.0,>=1.5.3 (from machine-learning-datasets)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (2.31.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (1.4.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.11.3 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (1.11.4)\n",
      "Collecting seaborn<0.13.0,>=0.12.2 (from machine-learning-datasets)\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: torchvision<0.17.0,>=0.16.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from machine-learning-datasets) (0.16.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from pandas<2.0.0,>=1.5.3->machine-learning-datasets) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from requests>=2.31.0->machine-learning-datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from requests>=2.31.0->machine-learning-datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from requests>=2.31.0->machine-learning-datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from requests>=2.31.0->machine-learning-datasets) (2023.11.17)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->machine-learning-datasets) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.2.2->machine-learning-datasets) (3.2.0)\n",
      "Requirement already satisfied: torch==2.1.2 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (2.1.2)\n",
      "Requirement already satisfied: filelock in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.1->machine-learning-datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from jinja2->torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/derekdeming/.pyenv/versions/3.10.8/lib/python3.10/site-packages (from sympy->torch==2.1.2->torchvision<0.17.0,>=0.16.0->machine-learning-datasets) (1.3.0)\n",
      "Downloading machine_learning_datasets-0.1.23-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python-4.9.0.80-cp37-abi3-macosx_11_0_arm64.whl (35.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.4/35.4 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python, pandas, seaborn, machine-learning-datasets\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sagemaker 2.203.1 requires urllib3<1.27, but you have urllib3 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed machine-learning-datasets-0.1.23 opencv-python-4.9.0.80 pandas-1.5.3 seaborn-0.12.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade machine-learning-datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import machine_learning_datasets as mldatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import machine_learning_datasets as mldatasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://raw.githubusercontent.com/caravanuden/cardio/master/cardio_train.csv downloaded to /Users/derekdeming/cs_projects/ml-interpretability/data/cardio_train.csv\n",
      "1 dataset files found in /Users/derekdeming/cs_projects/ml-interpretability/data folder\n",
      "parsing /Users/derekdeming/cs_projects/ml-interpretability/data/cardio_train.csv\n"
     ]
    }
   ],
   "source": [
    "cvd_df = mldatasets.load(\"cardiovascular-disease\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 70000 entries, 0 to 69999\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          70000 non-null  int64  \n",
      " 1   gender       70000 non-null  int64  \n",
      " 2   height       70000 non-null  int64  \n",
      " 3   weight       70000 non-null  float64\n",
      " 4   ap_hi        70000 non-null  int64  \n",
      " 5   ap_lo        70000 non-null  int64  \n",
      " 6   cholesterol  70000 non-null  int64  \n",
      " 7   gluc         70000 non-null  int64  \n",
      " 8   smoke        70000 non-null  int64  \n",
      " 9   alco         70000 non-null  int64  \n",
      " 10  active       70000 non-null  int64  \n",
      " 11  cardio       70000 non-null  int64  \n",
      "dtypes: float64(1), int64(11)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "cvd_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_df['age'] =  cvd_df['age'] / 365.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>53.304309</td>\n",
       "      <td>6.755152</td>\n",
       "      <td>29.564122</td>\n",
       "      <td>48.36272</td>\n",
       "      <td>53.945351</td>\n",
       "      <td>58.391742</td>\n",
       "      <td>64.924433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.349571</td>\n",
       "      <td>0.476838</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>164.359229</td>\n",
       "      <td>8.210126</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>159.00000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>74.205690</td>\n",
       "      <td>14.395757</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ap_hi</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>128.817286</td>\n",
       "      <td>154.011419</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>16020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ap_lo</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>96.630414</td>\n",
       "      <td>188.472530</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>80.00000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cholesterol</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.366871</td>\n",
       "      <td>0.680250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gluc</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>1.226457</td>\n",
       "      <td>0.572270</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoke</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.283484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alco</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.053771</td>\n",
       "      <td>0.225568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.803729</td>\n",
       "      <td>0.397179</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardio</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count        mean         std         min        25%  \\\n",
       "age          70000.0   53.304309    6.755152   29.564122   48.36272   \n",
       "gender       70000.0    1.349571    0.476838    1.000000    1.00000   \n",
       "height       70000.0  164.359229    8.210126   55.000000  159.00000   \n",
       "weight       70000.0   74.205690   14.395757   10.000000   65.00000   \n",
       "ap_hi        70000.0  128.817286  154.011419 -150.000000  120.00000   \n",
       "ap_lo        70000.0   96.630414  188.472530  -70.000000   80.00000   \n",
       "cholesterol  70000.0    1.366871    0.680250    1.000000    1.00000   \n",
       "gluc         70000.0    1.226457    0.572270    1.000000    1.00000   \n",
       "smoke        70000.0    0.088129    0.283484    0.000000    0.00000   \n",
       "alco         70000.0    0.053771    0.225568    0.000000    0.00000   \n",
       "active       70000.0    0.803729    0.397179    0.000000    1.00000   \n",
       "cardio       70000.0    0.499700    0.500003    0.000000    0.00000   \n",
       "\n",
       "                    50%         75%           max  \n",
       "age           53.945351   58.391742     64.924433  \n",
       "gender         1.000000    2.000000      2.000000  \n",
       "height       165.000000  170.000000    250.000000  \n",
       "weight        72.000000   82.000000    200.000000  \n",
       "ap_hi        120.000000  140.000000  16020.000000  \n",
       "ap_lo         80.000000   90.000000  11000.000000  \n",
       "cholesterol    1.000000    2.000000      3.000000  \n",
       "gluc           1.000000    1.000000      3.000000  \n",
       "smoke          0.000000    0.000000      1.000000  \n",
       "alco           0.000000    0.000000      1.000000  \n",
       "active         1.000000    1.000000      1.000000  \n",
       "cardio         0.000000    1.000000      1.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvd_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_df = cvd_df[(cvd_df['ap_lo'] <= 370) & (cvd_df['ap_lo'] > 0)].reset_index(drop=True)\n",
    "cvd_df = cvd_df[(cvd_df['ap_hi'] <= 370) & (cvd_df['ap_hi'] > 0)].reset_index(drop=True)\n",
    "cvd_df = cvd_df[cvd_df['ap_hi'] >= cvd_df['ap_lo']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007713466548296488\n"
     ]
    }
   ],
   "source": [
    "incorrect_l = cvd_df[\n",
    "    (cvd_df['ap_hi'] > 370)\n",
    "    | (cvd_df['ap_hi'] <= 40)\n",
    "    | (cvd_df['ap_lo'] > 370)\n",
    "    | (cvd_df['ap_lo'] <= 40)\n",
    "].index\n",
    "print(len(incorrect_l) / cvd_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_df.drop(incorrect_l, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvd_df = cvd_df[cvd_df['ap_hi'] >= cvd_df['ap_lo']].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = cvd_df['cardio']\n",
    "x = cvd_df.drop(columns=['cardio'], axis=1).copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning about interpretation method types and scopes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.562145\n",
      "         Iterations 6\n",
      "                         Results: Logit\n",
      "=================================================================\n",
      "Model:              Logit            Method:           MLE       \n",
      "Dependent Variable: cardio           Pseudo R-squared: 0.189     \n",
      "Date:               2024-04-21 23:11 AIC:              65636.3972\n",
      "No. Observations:   58359            BIC:              65744.0896\n",
      "Df Model:           11               Log-Likelihood:   -32806.   \n",
      "Df Residuals:       58347            LL-Null:          -40448.   \n",
      "Converged:          1.0000           LLR p-value:      0.0000    \n",
      "No. Iterations:     6.0000           Scale:            1.0000    \n",
      "-----------------------------------------------------------------\n",
      "               Coef.   Std.Err.    z     P>|z|   [0.025   0.975] \n",
      "-----------------------------------------------------------------\n",
      "const         -11.1677   0.2507 -44.5530 0.0000 -11.6590 -10.6764\n",
      "age             0.0504   0.0015  34.3350 0.0000   0.0475   0.0532\n",
      "gender         -0.0055   0.0238  -0.2329 0.8158  -0.0521   0.0410\n",
      "height         -0.0034   0.0014  -2.4417 0.0146  -0.0061  -0.0007\n",
      "weight          0.0107   0.0007  14.4555 0.0000   0.0093   0.0122\n",
      "ap_hi           0.0556   0.0010  55.3412 0.0000   0.0536   0.0575\n",
      "ap_lo           0.0114   0.0016   7.1754 0.0000   0.0083   0.0145\n",
      "cholesterol     0.4980   0.0169  29.4792 0.0000   0.4649   0.5311\n",
      "gluc           -0.1195   0.0192  -6.2198 0.0000  -0.1572  -0.0818\n",
      "smoke          -0.1442   0.0376  -3.8302 0.0001  -0.2180  -0.0704\n",
      "alco           -0.1920   0.0459  -4.1829 0.0000  -0.2819  -0.1020\n",
      "active         -0.2458   0.0238 -10.3248 0.0000  -0.2925  -0.1992\n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_model = sm.Logit(y_train, sm.add_constant(X_train))\n",
    "try:\n",
    "    log_result = log_model.fit()\n",
    "    print(log_result.summary2())\n",
    "except np.linalg.LinAlgError as e:\n",
    "    print(\"LinAlgError:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "why the exponential? \n",
    "\n",
    "well coefficients are the log odds, which are the logarithms of the odds. Odds are the probability of a positive case over the probability of a negative case, where the positive case is the label we are trying to predict \n",
    "\n",
    "the exponential function is the inverse of the log, so it can take any log odds and return the odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cholesterol    1.645409\n",
       "ap_hi          1.057123\n",
       "age            1.051662\n",
       "ap_lo          1.011482\n",
       "weight         1.010800\n",
       "height         0.996614\n",
       "gender         0.994480\n",
       "gluc           0.887356\n",
       "smoke          0.865710\n",
       "alco           0.825331\n",
       "active         0.782065\n",
       "const          0.000014\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_result.params).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see the binary categories vary little compared to the continuous variables such as weight, age, ap_hi/lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             6.753314\n",
       "gender          0.476652\n",
       "height          8.186996\n",
       "weight         14.331368\n",
       "ap_hi          16.682047\n",
       "ap_lo           9.434014\n",
       "cholesterol     0.678979\n",
       "gluc            0.570598\n",
       "smoke           0.283529\n",
       "alco            0.224476\n",
       "active          0.396201\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(X_train, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we take a look at the P > |z| column above. This is the p-value... when it is less than 0.05, we reject the null hyp that states that the coefficients is equal to zero. In other words, the corresponding feature is statistically significant \n",
    "\n",
    "however, when its above that number, especially by a large margin, there's no statistical evidence that it affects the predicted score, like the case for gender in the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we need to find the features that matter most\n",
    "\n",
    "one way to do this is by multiplying the coefficients by the std of the features. Incorporating the std accounts for differences in variances between features... so we should better see if gender really is irrelevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ap_hi          0.926707\n",
       "age            0.340174\n",
       "cholesterol    0.338124\n",
       "weight         0.153945\n",
       "ap_lo          0.107705\n",
       "active         0.097393\n",
       "gluc           0.068192\n",
       "alco           0.043093\n",
       "smoke          0.040886\n",
       "height         0.027770\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = log_result.params.drop(labels=['const', 'gender'])\n",
    "stdv = np.std(X_train, 0).drop(labels='gender')\n",
    "abs(coefs * stdv).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the table above can be interpreted as an approximation of risk factors from high to low according to the model \n",
    "\n",
    "it is model-specific not model-agnostic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our feature importance method shows that ap_hi, age, cholesterol, and weight are the parts that impact the whole the most\n",
    "\n",
    "feature importance is only one of many global modular interpretation methods but arguable the most important one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- global holistic interpretation: we can explain how a model makes predictions simply because we can comprehend the entire model at once with a complete understanding of the data and its a trained model \n",
    "\n",
    "-- global modular interpreation - in the same way we can explain the role of parts of an internal combustion engine in the whole process of turning fuel into movement, we can also do so with a model \n",
    "\n",
    "-- local single-prediction interpretation: the explanation of why a single prediction was made\n",
    "\n",
    "-- local group-prediction interp: apply the above to a group of predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
